{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f10aeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/.venv/hse/lib/python3.10/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#from prepare_dataset import CropTypesDataset\n",
    "from data.russia import Russia\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5839e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123ba276",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = os.path.join(os.environ[\"HOME\"], \"elects_data\", \"russia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3092bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache is activated and will be used if possible\n",
      "Data: train, year: 2018\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2018 year (train part) is loaded. It contains 8264 fields\n"
     ]
    }
   ],
   "source": [
    "rd = Russia(root=dataroot,\n",
    "           partition=\"train\",\n",
    "           sequencelength=5,\n",
    "           year=2018,\n",
    "           use_cache=True,\n",
    "           return_id=True,\n",
    "           broadcast_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e130d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = rd[\"X\"], rd[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda84b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8264, 50), (8264,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef67cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = [\n",
    "    \"B02\",\n",
    "    \"B03\",\n",
    "    \"B04\",\n",
    "    \"B05\",\n",
    "    \"B06\",\n",
    "    \"B07\",\n",
    "    \"B08\",\n",
    "    \"B8A\",\n",
    "    \"B11\",\n",
    "    \"B12\",\n",
    "]  # , 'NDVI'\n",
    "TIME_INTERVAL = [(4, 1), (9, 30)]\n",
    "region = \"russia\"\n",
    "year = 2018\n",
    "train_features_filepath = os.path.join(\n",
    "    dataroot, f\"{region}-{year}/train_features.csv.zip\"\n",
    ")\n",
    "test_features_filepath = os.path.join(\n",
    "    dataroot, f\"{region}-{year}/test_features.csv.zip\"\n",
    ")\n",
    "parcelsmapping_path = os.path.join(\n",
    "    dataroot, f\"{region}-{year}/parcelsmapping.csv\"\n",
    ")\n",
    "classmapping_path = os.path.join(dataroot, \"classmapping.csv\")\n",
    "\n",
    "\n",
    "def default_transform(x: np.ndarray, sequencelength: int) -> np.ndarray:\n",
    "    # choose with replacement if sequencelength smaller als choose_t\n",
    "    replace = False if x.shape[0] >= sequencelength else True\n",
    "    idxs = np.random.choice(x.shape[0], sequencelength, replace=replace)\n",
    "    idxs.sort()\n",
    "    x = x[idxs]\n",
    "    return x\n",
    "\n",
    "\n",
    "cd = CropTypesDataset(\n",
    "    features_filepath=train_features_filepath,\n",
    "    classmapping_path=classmapping_path,\n",
    "    fieldsmapping_path=parcelsmapping_path,\n",
    "    bands=BANDS,\n",
    "    time_interval=TIME_INTERVAL,\n",
    "    sequencelength=5,\n",
    "    transform=default_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3caed",
   "metadata": {},
   "source": [
    "# Part 1: Classical Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2efcb",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16cf08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/pavel/elects_data/russia/russia-2021/train_features.csv.zip\")\n",
    "test = pd.read_csv(\"/home/pavel/elects_data/russia/russia-2021/test_features.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e34db98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((837200, 18), (217682, 18))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dcda7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 837200 entries, 0 to 837199\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   index                   837200 non-null  int64  \n",
      " 1   timestamp               837200 non-null  object \n",
      " 2   field_id                837200 non-null  int64  \n",
      " 3   eopatch                 837200 non-null  object \n",
      " 4   parcel_pixels           837200 non-null  int64  \n",
      " 5   B02                     837200 non-null  float64\n",
      " 6   B03                     837200 non-null  float64\n",
      " 7   B04                     837200 non-null  float64\n",
      " 8   B05                     837200 non-null  float64\n",
      " 9   B06                     837200 non-null  float64\n",
      " 10  B07                     837200 non-null  float64\n",
      " 11  B08                     837200 non-null  float64\n",
      " 12  B8A                     837200 non-null  float64\n",
      " 13  B11                     837200 non-null  float64\n",
      " 14  B12                     837200 non-null  float64\n",
      " 15  parcell_cloud_coverage  837200 non-null  float64\n",
      " 16  parcell_data_coverage   837200 non-null  float64\n",
      " 17  class_id                837200 non-null  int64  \n",
      "dtypes: float64(12), int64(4), object(2)\n",
      "memory usage: 115.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f346483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>field_id</th>\n",
       "      <th>eopatch</th>\n",
       "      <th>parcel_pixels</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>parcell_cloud_coverage</th>\n",
       "      <th>parcell_data_coverage</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-01</th>\n",
       "      <td>0</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>856</td>\n",
       "      <td>440.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>437.5</td>\n",
       "      <td>470.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>793.5</td>\n",
       "      <td>0.450025</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-06</th>\n",
       "      <td>1</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>6151</td>\n",
       "      <td>211.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-11</th>\n",
       "      <td>2</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>6151</td>\n",
       "      <td>297.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-01</th>\n",
       "      <td>3</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>6151</td>\n",
       "      <td>471.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-16</th>\n",
       "      <td>4</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>5545</td>\n",
       "      <td>317.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>0.051504</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-10</th>\n",
       "      <td>5</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>5479</td>\n",
       "      <td>441.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>991.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1511.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.057114</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-15</th>\n",
       "      <td>6</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>6151</td>\n",
       "      <td>411.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>2433.0</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-20</th>\n",
       "      <td>7</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>6151</td>\n",
       "      <td>472.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>2812.0</td>\n",
       "      <td>2887.0</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>8</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>6151</td>\n",
       "      <td>392.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>3026.0</td>\n",
       "      <td>2952.0</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>9</td>\n",
       "      <td>2591</td>\n",
       "      <td>37UCS_2_1</td>\n",
       "      <td>1330</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>3884.0</td>\n",
       "      <td>5324.0</td>\n",
       "      <td>5152.0</td>\n",
       "      <td>5431.0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>0.409740</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  field_id    eopatch  parcel_pixels     B02     B03     B04  \\\n",
       "timestamp                                                                       \n",
       "2021-04-01      0      2591  37UCS_2_1            856   440.0   389.0   437.5   \n",
       "2021-04-06      1      2591  37UCS_2_1           6151   211.0   277.0   402.0   \n",
       "2021-04-11      2      2591  37UCS_2_1           6151   297.0   323.0   457.0   \n",
       "2021-05-01      3      2591  37UCS_2_1           6151   471.0   484.0   600.0   \n",
       "2021-05-16      4      2591  37UCS_2_1           5545   317.0   337.0   256.0   \n",
       "2021-06-10      5      2591  37UCS_2_1           5479   441.0   472.0   446.0   \n",
       "2021-06-15      6      2591  37UCS_2_1           6151   411.0   549.0   492.0   \n",
       "2021-06-20      7      2591  37UCS_2_1           6151   472.0   646.0   462.0   \n",
       "2021-06-25      8      2591  37UCS_2_1           6151   392.0   559.0   386.0   \n",
       "2021-06-30      9      2591  37UCS_2_1           1330  1335.0  1412.0  1137.0   \n",
       "\n",
       "               B05     B06     B07     B08     B8A     B11     B12  \\\n",
       "timestamp                                                            \n",
       "2021-04-01   470.0   475.0   509.0   561.0   565.0   988.0   793.5   \n",
       "2021-04-06   474.0   511.0   567.0   656.0   689.0  1766.0  1633.0   \n",
       "2021-04-11   517.0   563.0   630.0   749.0   767.0  1991.0  1913.0   \n",
       "2021-05-01   694.0   774.0   865.0   983.0  1030.0  2411.0  2295.0   \n",
       "2021-05-16   371.0   645.0   674.0   678.0   702.0   711.0   533.0   \n",
       "2021-06-10   572.0   867.0   991.0  1040.0  1072.0  1511.0  1277.0   \n",
       "2021-06-15   759.0  1429.0  1622.0  1654.0  1769.0  2433.0  1914.0   \n",
       "2021-06-20   795.0  2233.0  2769.0  2812.0  2887.0  2232.0  1508.0   \n",
       "2021-06-25   703.0  2304.0  3026.0  2952.0  3167.0  1998.0  1158.0   \n",
       "2021-06-30  1549.0  3884.0  5324.0  5152.0  5431.0  2590.0  1557.0   \n",
       "\n",
       "            parcell_cloud_coverage  parcell_data_coverage  class_id  \n",
       "timestamp                                                            \n",
       "2021-04-01                0.450025               0.522777         0  \n",
       "2021-04-06                0.000000               0.522777         0  \n",
       "2021-04-11                0.000000               0.522777         0  \n",
       "2021-05-01                0.000000               0.522777         0  \n",
       "2021-05-16                0.051504               0.522777         0  \n",
       "2021-06-10                0.057114               0.522777         0  \n",
       "2021-06-15                0.000000               0.522777         0  \n",
       "2021-06-20                0.000000               0.522777         0  \n",
       "2021-06-25                0.000000               0.522777         0  \n",
       "2021-06-30                0.409740               0.522777         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc34b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train\\\n",
    "    .pivot(\n",
    "        index=\"field_id\",\n",
    "        columns=\"timestamp\",\n",
    "        values=[\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"])\\\n",
    "    .reset_index(drop=True)\n",
    "X_train.columns = [f\"{a}_{b}\" for a, b in X_train.columns]\n",
    "X_train.interpolate(method=\"linear\", axis=1, inplace=True)\n",
    "X_train = X_train.fillna(method=\"ffill\", axis=1).fillna(method=\"bfill\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42487216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30417,),\n",
       " field_id\n",
       " 2591    0\n",
       " 2592    0\n",
       " 2593    0\n",
       " 2594    0\n",
       " 2595    0\n",
       " Name: class_id, dtype: int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train.groupby(\"field_id\").agg({\"class_id\": max})[\"class_id\"]\n",
    "y_train.shape, y.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d570aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02_2021-04-01</th>\n",
       "      <th>B02_2021-04-02</th>\n",
       "      <th>B02_2021-04-03</th>\n",
       "      <th>B02_2021-04-04</th>\n",
       "      <th>B02_2021-04-05</th>\n",
       "      <th>B02_2021-04-06</th>\n",
       "      <th>B02_2021-04-07</th>\n",
       "      <th>B02_2021-04-08</th>\n",
       "      <th>B02_2021-04-09</th>\n",
       "      <th>B02_2021-04-10</th>\n",
       "      <th>...</th>\n",
       "      <th>B12_2021-09-21</th>\n",
       "      <th>B12_2021-09-22</th>\n",
       "      <th>B12_2021-09-23</th>\n",
       "      <th>B12_2021-09-24</th>\n",
       "      <th>B12_2021-09-25</th>\n",
       "      <th>B12_2021-09-26</th>\n",
       "      <th>B12_2021-09-27</th>\n",
       "      <th>B12_2021-09-28</th>\n",
       "      <th>B12_2021-09-29</th>\n",
       "      <th>B12_2021-09-30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>440.0</td>\n",
       "      <td>394.200000</td>\n",
       "      <td>348.400000</td>\n",
       "      <td>302.600000</td>\n",
       "      <td>256.800000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>228.200000</td>\n",
       "      <td>245.400000</td>\n",
       "      <td>262.60000</td>\n",
       "      <td>279.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "      <td>2707.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576.0</td>\n",
       "      <td>507.200000</td>\n",
       "      <td>438.400000</td>\n",
       "      <td>369.600000</td>\n",
       "      <td>300.800000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>248.600000</td>\n",
       "      <td>265.200000</td>\n",
       "      <td>281.80000</td>\n",
       "      <td>298.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "      <td>2676.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382.0</td>\n",
       "      <td>354.200000</td>\n",
       "      <td>326.400000</td>\n",
       "      <td>298.600000</td>\n",
       "      <td>270.800000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>269.400000</td>\n",
       "      <td>295.800000</td>\n",
       "      <td>322.20000</td>\n",
       "      <td>348.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "      <td>2883.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1670.0</td>\n",
       "      <td>1385.969331</td>\n",
       "      <td>1101.938661</td>\n",
       "      <td>817.907992</td>\n",
       "      <td>533.877323</td>\n",
       "      <td>249.846653</td>\n",
       "      <td>263.136106</td>\n",
       "      <td>276.425558</td>\n",
       "      <td>289.71501</td>\n",
       "      <td>303.004462</td>\n",
       "      <td>...</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "      <td>2798.38986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195.0</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>211.800000</td>\n",
       "      <td>228.600000</td>\n",
       "      <td>245.40000</td>\n",
       "      <td>262.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "      <td>2854.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1830 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   B02_2021-04-01  B02_2021-04-02  B02_2021-04-03  B02_2021-04-04  \\\n",
       "0           440.0      394.200000      348.400000      302.600000   \n",
       "1           576.0      507.200000      438.400000      369.600000   \n",
       "2           382.0      354.200000      326.400000      298.600000   \n",
       "3          1670.0     1385.969331     1101.938661      817.907992   \n",
       "4           195.0      195.000000      195.000000      195.000000   \n",
       "\n",
       "   B02_2021-04-05  B02_2021-04-06  B02_2021-04-07  B02_2021-04-08  \\\n",
       "0      256.800000      211.000000      228.200000      245.400000   \n",
       "1      300.800000      232.000000      248.600000      265.200000   \n",
       "2      270.800000      243.000000      269.400000      295.800000   \n",
       "3      533.877323      249.846653      263.136106      276.425558   \n",
       "4      195.000000      195.000000      211.800000      228.600000   \n",
       "\n",
       "   B02_2021-04-09  B02_2021-04-10  ...  B12_2021-09-21  B12_2021-09-22  \\\n",
       "0       262.60000      279.800000  ...      2707.00000      2707.00000   \n",
       "1       281.80000      298.400000  ...      2676.00000      2676.00000   \n",
       "2       322.20000      348.600000  ...      2883.00000      2883.00000   \n",
       "3       289.71501      303.004462  ...      2798.38986      2798.38986   \n",
       "4       245.40000      262.200000  ...      2854.00000      2854.00000   \n",
       "\n",
       "   B12_2021-09-23  B12_2021-09-24  B12_2021-09-25  B12_2021-09-26  \\\n",
       "0      2707.00000      2707.00000      2707.00000      2707.00000   \n",
       "1      2676.00000      2676.00000      2676.00000      2676.00000   \n",
       "2      2883.00000      2883.00000      2883.00000      2883.00000   \n",
       "3      2798.38986      2798.38986      2798.38986      2798.38986   \n",
       "4      2854.00000      2854.00000      2854.00000      2854.00000   \n",
       "\n",
       "   B12_2021-09-27  B12_2021-09-28  B12_2021-09-29  B12_2021-09-30  \n",
       "0      2707.00000      2707.00000      2707.00000      2707.00000  \n",
       "1      2676.00000      2676.00000      2676.00000      2676.00000  \n",
       "2      2883.00000      2883.00000      2883.00000      2883.00000  \n",
       "3      2798.38986      2798.38986      2798.38986      2798.38986  \n",
       "4      2854.00000      2854.00000      2854.00000      2854.00000  \n",
       "\n",
       "[5 rows x 1830 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10749d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "field_id\n",
       "2591     0\n",
       "2592     0\n",
       "2593     0\n",
       "2594     0\n",
       "2595     0\n",
       "        ..\n",
       "82578    3\n",
       "88485    3\n",
       "88493    3\n",
       "89284    3\n",
       "89301    3\n",
       "Name: class_id, Length: 30417, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fd9ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test\\\n",
    "    .pivot(\n",
    "        index=\"field_id\",\n",
    "        columns=\"timestamp\",\n",
    "        values=[\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"])\\\n",
    "    .reset_index(drop=True)\n",
    "X_test.columns = [f\"{a}_{b}\" for a, b in X_test.columns]\n",
    "X_test.interpolate(method=\"linear\", axis=1, inplace=True)\n",
    "X_test = X_test.fillna(method=\"ffill\", axis=1).fillna(method=\"bfill\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "603ab1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30417,),\n",
       " field_id\n",
       " 2591    0\n",
       " 2592    0\n",
       " 2593    0\n",
       " 2594    0\n",
       " 2595    0\n",
       " Name: class_id, dtype: int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = train.groupby(\"field_id\").agg({\"class_id\": max})[\"class_id\"]\n",
    "y_test.shape, y.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa7dd3",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6caa8",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30eb154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b098618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=10; total time=   3.1s\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=10; total time=   3.1s\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=10; total time=   3.2s\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=40; total time=  12.0s\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=40; total time=  12.0s\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=40; total time=  12.3s\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=70; total time=  21.2s\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=70; total time=  20.5s\n",
      "[CV] END ..max_depth=3, min_samples_split=5, n_estimators=70; total time=  21.5s\n",
      "[CV] END .max_depth=3, min_samples_split=5, n_estimators=100; total time=  30.0s\n",
      "[CV] END .max_depth=3, min_samples_split=5, n_estimators=100; total time=  29.6s\n",
      "[CV] END .max_depth=3, min_samples_split=5, n_estimators=100; total time=  29.5s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=10; total time=   3.2s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=10; total time=   3.3s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=10; total time=   3.1s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=40; total time=  11.9s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=40; total time=  11.8s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=40; total time=  12.1s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=70; total time=  21.1s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=70; total time=  20.8s\n",
      "[CV] END .max_depth=3, min_samples_split=15, n_estimators=70; total time=  20.7s\n",
      "[CV] END max_depth=3, min_samples_split=15, n_estimators=100; total time=  29.3s\n",
      "[CV] END max_depth=3, min_samples_split=15, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=3, min_samples_split=15, n_estimators=100; total time=  28.9s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=10; total time=   3.1s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=10; total time=   3.1s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=10; total time=   3.1s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=40; total time=  11.5s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=40; total time=  11.5s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=40; total time=  11.5s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=70; total time=  20.1s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=70; total time=  20.5s\n",
      "[CV] END .max_depth=3, min_samples_split=25, n_estimators=70; total time=  19.9s\n",
      "[CV] END max_depth=3, min_samples_split=25, n_estimators=100; total time=  28.4s\n",
      "[CV] END max_depth=3, min_samples_split=25, n_estimators=100; total time=  28.3s\n",
      "[CV] END max_depth=3, min_samples_split=25, n_estimators=100; total time=  28.4s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=10; total time=   5.6s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=10; total time=   5.6s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=10; total time=   5.7s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=40; total time=  21.9s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=40; total time=  21.9s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=40; total time=  22.3s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=70; total time=  38.1s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=70; total time=  38.0s\n",
      "[CV] END ..max_depth=6, min_samples_split=5, n_estimators=70; total time=  38.2s\n",
      "[CV] END .max_depth=6, min_samples_split=5, n_estimators=100; total time=  54.1s\n",
      "[CV] END .max_depth=6, min_samples_split=5, n_estimators=100; total time=  54.3s\n",
      "[CV] END .max_depth=6, min_samples_split=5, n_estimators=100; total time=  56.1s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=10; total time=   5.8s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=10; total time=   5.6s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=10; total time=   5.9s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=40; total time=  22.1s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=40; total time=  21.8s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=40; total time=  22.3s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=70; total time=  38.1s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=70; total time=  38.0s\n",
      "[CV] END .max_depth=6, min_samples_split=15, n_estimators=70; total time=  38.2s\n",
      "[CV] END max_depth=6, min_samples_split=15, n_estimators=100; total time=  54.2s\n",
      "[CV] END max_depth=6, min_samples_split=15, n_estimators=100; total time=  54.3s\n",
      "[CV] END max_depth=6, min_samples_split=15, n_estimators=100; total time=  54.4s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=10; total time=   5.7s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=10; total time=   5.6s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=10; total time=   5.7s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=40; total time=  21.9s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=40; total time=  21.8s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=40; total time=  21.9s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=70; total time=  38.0s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=70; total time=  37.9s\n",
      "[CV] END .max_depth=6, min_samples_split=25, n_estimators=70; total time=  38.1s\n",
      "[CV] END max_depth=6, min_samples_split=25, n_estimators=100; total time=  54.1s\n",
      "[CV] END max_depth=6, min_samples_split=25, n_estimators=100; total time=  56.2s\n",
      "[CV] END max_depth=6, min_samples_split=25, n_estimators=100; total time= 1.0min\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=10; total time=   8.4s\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=10; total time=   8.2s\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=10; total time=   8.1s\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=40; total time=  31.3s\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=40; total time=  31.2s\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=40; total time=  31.4s\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=70; total time=  54.7s\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=70; total time=  54.4s\n",
      "[CV] END ..max_depth=9, min_samples_split=5, n_estimators=70; total time=  54.6s\n",
      "[CV] END .max_depth=9, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END .max_depth=9, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END .max_depth=9, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=10; total time=   8.0s\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=10; total time=   8.0s\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=10; total time=   8.1s\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=40; total time=  31.1s\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=40; total time=  31.1s\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=40; total time=  31.3s\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=70; total time=  54.7s\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=70; total time=  54.4s\n",
      "[CV] END .max_depth=9, min_samples_split=15, n_estimators=70; total time=  54.9s\n",
      "[CV] END max_depth=9, min_samples_split=15, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=9, min_samples_split=15, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=9, min_samples_split=15, n_estimators=100; total time= 1.3min\n",
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=10; total time=   7.9s\n",
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=10; total time=   8.0s\n",
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=10; total time=   8.0s\n",
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=40; total time=  30.9s\n",
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=40; total time=  31.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=40; total time=  32.0s\n",
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=70; total time=  54.1s\n",
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=70; total time=  54.2s\n",
      "[CV] END .max_depth=9, min_samples_split=25, n_estimators=70; total time=  54.9s\n",
      "[CV] END max_depth=9, min_samples_split=25, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=9, min_samples_split=25, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=9, min_samples_split=25, n_estimators=100; total time= 1.3min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(3, 11, 3),\n",
       "                         &#x27;min_samples_split&#x27;: range(5, 26, 10),\n",
       "                         &#x27;n_estimators&#x27;: range(10, 110, 30)},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(3, 11, 3),\n",
       "                         &#x27;min_samples_split&#x27;: range(5, 26, 10),\n",
       "                         &#x27;n_estimators&#x27;: range(10, 110, 30)},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=1,\n",
       "             param_grid={'max_depth': range(3, 11, 3),\n",
       "                         'min_samples_split': range(5, 26, 10),\n",
       "                         'n_estimators': range(10, 110, 30)},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gs_params = {\n",
    "    \"n_estimators\": range(10, 110, 30),\n",
    "    \"max_depth\": range(3, 11, 3),\n",
    "    \"min_samples_split\": range(5, 26, 10)\n",
    "}\n",
    "\n",
    "gs1 = GridSearchCV(rfc, gs_params, scoring=\"accuracy\", n_jobs=1, verbose=2, cv=3)\n",
    "gs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1702974e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7124963014103954, RandomForestClassifier(max_depth=9, min_samples_split=25))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_score_, gs1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "717196f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- B02_2021-09-24\n- B03_2021-09-24\n- B04_2021-09-24\n- B05_2021-09-24\n- B06_2021-09-24\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mgs1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m accuracy_score(y_test,y_pred), f1_score(y_test,y_pred)\n",
      "File \u001b[0;32m/media/pavel/DATA/miniconda3-ubuntu1604/envs/python310/lib/python3.10/site-packages/sklearn/model_selection/_search.py:500\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    499\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pavel/DATA/miniconda3-ubuntu1604/envs/python310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:821\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 821\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    824\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/media/pavel/DATA/miniconda3-ubuntu1604/envs/python310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:863\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    861\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    866\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/media/pavel/DATA/miniconda3-ubuntu1604/envs/python310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:603\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 603\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/pavel/DATA/miniconda3-ubuntu1604/envs/python310/lib/python3.10/site-packages/sklearn/base.py:518\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    455\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    460\u001b[0m ):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    522\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         )\n",
      "File \u001b[0;32m/media/pavel/DATA/miniconda3-ubuntu1604/envs/python310/lib/python3.10/site-packages/sklearn/base.py:451\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    447\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     )\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- B02_2021-09-24\n- B03_2021-09-24\n- B04_2021-09-24\n- B05_2021-09-24\n- B06_2021-09-24\n- ...\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs1.predict(X_test)\n",
    "accuracy_score(y_test,y_pred), f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c99365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9c2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    dataset: str = \"russia\"\n",
    "    alpha: float = 0.5\n",
    "    epsilon: float = 10\n",
    "    learning_rate: float = 10e-3\n",
    "    weight_decay: float = 0\n",
    "    patience: int = 30\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"               \n",
    "    epochs: int = 50\n",
    "    sequencelength: int = 183\n",
    "    batchsize: int = 128\n",
    "    dataroot: str = os.path.join(os.environ[\"HOME\"],\"elects_data\")\n",
    "    snapshot: str = \"snapshots/model.pth\"\n",
    "    resume: bool = False\n",
    "    year: int = 2021\n",
    "    use_cache: bool = True\n",
    "    model: str = \"earlyrnn\"\n",
    "    n_months: int = 6\n",
    "    visualize: bool = False\n",
    "    hyperparameters: dict = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b4347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache is activated and will be used if possible\n",
      "Data: train, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (train part) is loaded. It contains 30417 fields\n",
      "Cache is activated and will be used if possible\n",
      "Data: test, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (test part) is loaded. It contains 7595 fields\n",
      "X shape: (30417, 100) y shape: (30417,)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Cache is activated and will be used if possible\n",
      "Data: train, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (train part) is loaded. It contains 30417 fields\n",
      "Cache is activated and will be used if possible\n",
      "Data: test, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (test part) is loaded. It contains 7595 fields\n",
      "X shape: (30417, 200) y shape: (30417,)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Cache is activated and will be used if possible\n",
      "Data: train, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (train part) is loaded. It contains 30417 fields\n",
      "Cache is activated and will be used if possible\n",
      "Data: test, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (test part) is loaded. It contains 7595 fields\n",
      "X shape: (30417, 300) y shape: (30417,)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Cache is activated and will be used if possible\n",
      "Data: train, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (train part) is loaded. It contains 30417 fields\n",
      "Cache is activated and will be used if possible\n",
      "Data: test, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (test part) is loaded. It contains 7595 fields\n",
      "X shape: (30417, 400) y shape: (30417,)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Cache is activated and will be used if possible\n",
      "Data: train, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (train part) is loaded. It contains 30417 fields\n",
      "Cache is activated and will be used if possible\n",
      "Data: test, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (test part) is loaded. It contains 7595 fields\n",
      "X shape: (30417, 500) y shape: (30417,)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Cache is activated and will be used if possible\n",
      "Data: train, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (train part) is loaded. It contains 30417 fields\n",
      "Cache is activated and will be used if possible\n",
      "Data: test, year: 2021\n",
      "Trying to use cache\n",
      "Loading X and y from cache\n",
      "Russia dataset for 2021 year (test part) is loaded. It contains 7595 fields\n",
      "X shape: (30417, 600) y shape: (30417,)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "rf_stats = []\n",
    "for n_months, sequencelength in zip(range(1, 7), range(10, 70, 10)):\n",
    "    args = TrainConfig(model=\"rf\",\n",
    "                       n_months=n_months,\n",
    "                       sequencelength=sequencelength,\n",
    "                       hyperparameters={\"n_estimators\": range(10, 110, 20)})\n",
    "    best_model, train_stats = train(args)\n",
    "    rf_stats.append(train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebafea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dfs = []\n",
    "for i, stat in enumerate(rf_stats):\n",
    "    df = pd.DataFrame(stat)\n",
    "    df[\"n_months\"] = i + 1\n",
    "    rf_dfs.append(df)\n",
    "rf_stat_df = pd.concat(rf_dfs)\n",
    "rf_stat_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03fe4356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_fscore</th>\n",
       "      <th>split0_test_kappa</th>\n",
       "      <th>split1_test_kappa</th>\n",
       "      <th>split2_test_kappa</th>\n",
       "      <th>split3_test_kappa</th>\n",
       "      <th>split4_test_kappa</th>\n",
       "      <th>mean_test_kappa</th>\n",
       "      <th>std_test_kappa</th>\n",
       "      <th>rank_test_kappa</th>\n",
       "      <th>n_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.530161</td>\n",
       "      <td>0.536271</td>\n",
       "      <td>0.053766</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.516437</td>\n",
       "      <td>0.533531</td>\n",
       "      <td>0.535427</td>\n",
       "      <td>0.518823</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.434456</td>\n",
       "      <td>0.455954</td>\n",
       "      <td>0.453075</td>\n",
       "      <td>0.434335</td>\n",
       "      <td>0.443335</td>\n",
       "      <td>0.444231</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.307498</td>\n",
       "      <td>1.239440</td>\n",
       "      <td>0.121411</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>0.567061</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.579813</td>\n",
       "      <td>0.565839</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>0.512435</td>\n",
       "      <td>0.503674</td>\n",
       "      <td>0.487696</td>\n",
       "      <td>0.503190</td>\n",
       "      <td>0.499819</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.955016</td>\n",
       "      <td>3.128957</td>\n",
       "      <td>0.178361</td>\n",
       "      <td>0.025497</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.583498</td>\n",
       "      <td>0.592045</td>\n",
       "      <td>0.590334</td>\n",
       "      <td>0.586060</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.522253</td>\n",
       "      <td>0.516077</td>\n",
       "      <td>0.511640</td>\n",
       "      <td>0.523168</td>\n",
       "      <td>0.516869</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.585612</td>\n",
       "      <td>4.652533</td>\n",
       "      <td>0.208319</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>70</td>\n",
       "      <td>{'n_estimators': 70}</td>\n",
       "      <td>0.588264</td>\n",
       "      <td>0.600756</td>\n",
       "      <td>0.601184</td>\n",
       "      <td>0.589347</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516186</td>\n",
       "      <td>0.532388</td>\n",
       "      <td>0.528745</td>\n",
       "      <td>0.515077</td>\n",
       "      <td>0.527616</td>\n",
       "      <td>0.524002</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.468254</td>\n",
       "      <td>6.151401</td>\n",
       "      <td>0.256024</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>90</td>\n",
       "      <td>{'n_estimators': 90}</td>\n",
       "      <td>0.592373</td>\n",
       "      <td>0.597962</td>\n",
       "      <td>0.597238</td>\n",
       "      <td>0.591156</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521004</td>\n",
       "      <td>0.528986</td>\n",
       "      <td>0.523690</td>\n",
       "      <td>0.516920</td>\n",
       "      <td>0.523799</td>\n",
       "      <td>0.522880</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.078377</td>\n",
       "      <td>0.816084</td>\n",
       "      <td>0.051993</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.575937</td>\n",
       "      <td>0.587114</td>\n",
       "      <td>0.592964</td>\n",
       "      <td>0.585566</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.505767</td>\n",
       "      <td>0.519083</td>\n",
       "      <td>0.522750</td>\n",
       "      <td>0.513864</td>\n",
       "      <td>0.512201</td>\n",
       "      <td>0.514733</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.323907</td>\n",
       "      <td>2.623709</td>\n",
       "      <td>0.109219</td>\n",
       "      <td>0.013138</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>0.617357</td>\n",
       "      <td>0.625904</td>\n",
       "      <td>0.639816</td>\n",
       "      <td>0.626336</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.552271</td>\n",
       "      <td>0.562799</td>\n",
       "      <td>0.576646</td>\n",
       "      <td>0.560217</td>\n",
       "      <td>0.554982</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.277406</td>\n",
       "      <td>4.429330</td>\n",
       "      <td>0.164226</td>\n",
       "      <td>0.016719</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.634287</td>\n",
       "      <td>0.647272</td>\n",
       "      <td>0.648529</td>\n",
       "      <td>0.646227</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571806</td>\n",
       "      <td>0.587935</td>\n",
       "      <td>0.586828</td>\n",
       "      <td>0.583978</td>\n",
       "      <td>0.572795</td>\n",
       "      <td>0.580668</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49.724756</td>\n",
       "      <td>6.115824</td>\n",
       "      <td>0.229821</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>70</td>\n",
       "      <td>{'n_estimators': 70}</td>\n",
       "      <td>0.636259</td>\n",
       "      <td>0.648751</td>\n",
       "      <td>0.652474</td>\n",
       "      <td>0.650337</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.574069</td>\n",
       "      <td>0.589371</td>\n",
       "      <td>0.591202</td>\n",
       "      <td>0.588727</td>\n",
       "      <td>0.578045</td>\n",
       "      <td>0.584283</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60.738212</td>\n",
       "      <td>8.817731</td>\n",
       "      <td>0.249882</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>90</td>\n",
       "      <td>{'n_estimators': 90}</td>\n",
       "      <td>0.645135</td>\n",
       "      <td>0.644806</td>\n",
       "      <td>0.655104</td>\n",
       "      <td>0.652310</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584666</td>\n",
       "      <td>0.584755</td>\n",
       "      <td>0.594411</td>\n",
       "      <td>0.590973</td>\n",
       "      <td>0.578874</td>\n",
       "      <td>0.586736</td>\n",
       "      <td>0.005420</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.740726</td>\n",
       "      <td>0.954207</td>\n",
       "      <td>0.056579</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.591552</td>\n",
       "      <td>0.613248</td>\n",
       "      <td>0.617458</td>\n",
       "      <td>0.617294</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.524316</td>\n",
       "      <td>0.550588</td>\n",
       "      <td>0.552204</td>\n",
       "      <td>0.551157</td>\n",
       "      <td>0.537681</td>\n",
       "      <td>0.543189</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.455367</td>\n",
       "      <td>1.819653</td>\n",
       "      <td>0.114280</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>0.644806</td>\n",
       "      <td>0.654504</td>\n",
       "      <td>0.659543</td>\n",
       "      <td>0.662009</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.585368</td>\n",
       "      <td>0.597401</td>\n",
       "      <td>0.600736</td>\n",
       "      <td>0.603231</td>\n",
       "      <td>0.591567</td>\n",
       "      <td>0.595661</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>47.267535</td>\n",
       "      <td>3.130625</td>\n",
       "      <td>0.169432</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.649080</td>\n",
       "      <td>0.665680</td>\n",
       "      <td>0.674010</td>\n",
       "      <td>0.678777</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.590015</td>\n",
       "      <td>0.610605</td>\n",
       "      <td>0.618004</td>\n",
       "      <td>0.622958</td>\n",
       "      <td>0.602611</td>\n",
       "      <td>0.608839</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>78.625676</td>\n",
       "      <td>8.368828</td>\n",
       "      <td>0.221194</td>\n",
       "      <td>0.023540</td>\n",
       "      <td>70</td>\n",
       "      <td>{'n_estimators': 70}</td>\n",
       "      <td>0.661078</td>\n",
       "      <td>0.675871</td>\n",
       "      <td>0.676640</td>\n",
       "      <td>0.681243</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604209</td>\n",
       "      <td>0.622724</td>\n",
       "      <td>0.621108</td>\n",
       "      <td>0.625771</td>\n",
       "      <td>0.603546</td>\n",
       "      <td>0.615472</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81.088351</td>\n",
       "      <td>7.619692</td>\n",
       "      <td>0.271908</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>90</td>\n",
       "      <td>{'n_estimators': 90}</td>\n",
       "      <td>0.656640</td>\n",
       "      <td>0.679980</td>\n",
       "      <td>0.677955</td>\n",
       "      <td>0.680585</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598885</td>\n",
       "      <td>0.627120</td>\n",
       "      <td>0.622391</td>\n",
       "      <td>0.624991</td>\n",
       "      <td>0.606015</td>\n",
       "      <td>0.615880</td>\n",
       "      <td>0.011295</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.768281</td>\n",
       "      <td>1.539505</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.626068</td>\n",
       "      <td>0.630342</td>\n",
       "      <td>0.635048</td>\n",
       "      <td>0.634227</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564429</td>\n",
       "      <td>0.569494</td>\n",
       "      <td>0.573726</td>\n",
       "      <td>0.571556</td>\n",
       "      <td>0.566107</td>\n",
       "      <td>0.569062</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.260707</td>\n",
       "      <td>3.113115</td>\n",
       "      <td>0.127460</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>0.655654</td>\n",
       "      <td>0.678337</td>\n",
       "      <td>0.684366</td>\n",
       "      <td>0.679928</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.597852</td>\n",
       "      <td>0.625432</td>\n",
       "      <td>0.630740</td>\n",
       "      <td>0.624605</td>\n",
       "      <td>0.615017</td>\n",
       "      <td>0.618729</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51.962351</td>\n",
       "      <td>5.990119</td>\n",
       "      <td>0.179448</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.669461</td>\n",
       "      <td>0.688692</td>\n",
       "      <td>0.694065</td>\n",
       "      <td>0.689462</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.613897</td>\n",
       "      <td>0.637007</td>\n",
       "      <td>0.641839</td>\n",
       "      <td>0.636136</td>\n",
       "      <td>0.617481</td>\n",
       "      <td>0.629272</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73.553722</td>\n",
       "      <td>7.736031</td>\n",
       "      <td>0.237106</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>70</td>\n",
       "      <td>{'n_estimators': 70}</td>\n",
       "      <td>0.678008</td>\n",
       "      <td>0.693787</td>\n",
       "      <td>0.697682</td>\n",
       "      <td>0.699984</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.624237</td>\n",
       "      <td>0.643239</td>\n",
       "      <td>0.646128</td>\n",
       "      <td>0.648053</td>\n",
       "      <td>0.629001</td>\n",
       "      <td>0.638131</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>91.918373</td>\n",
       "      <td>8.668600</td>\n",
       "      <td>0.300437</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>90</td>\n",
       "      <td>{'n_estimators': 90}</td>\n",
       "      <td>0.679323</td>\n",
       "      <td>0.696252</td>\n",
       "      <td>0.699326</td>\n",
       "      <td>0.693243</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625638</td>\n",
       "      <td>0.646238</td>\n",
       "      <td>0.647833</td>\n",
       "      <td>0.640170</td>\n",
       "      <td>0.633175</td>\n",
       "      <td>0.638611</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.585349</td>\n",
       "      <td>1.196537</td>\n",
       "      <td>0.060047</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.639053</td>\n",
       "      <td>0.659050</td>\n",
       "      <td>0.648693</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.566923</td>\n",
       "      <td>0.580541</td>\n",
       "      <td>0.602343</td>\n",
       "      <td>0.587852</td>\n",
       "      <td>0.577097</td>\n",
       "      <td>0.582951</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>35.660682</td>\n",
       "      <td>4.929442</td>\n",
       "      <td>0.132769</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>0.672913</td>\n",
       "      <td>0.690993</td>\n",
       "      <td>0.698833</td>\n",
       "      <td>0.693737</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.618431</td>\n",
       "      <td>0.640877</td>\n",
       "      <td>0.647954</td>\n",
       "      <td>0.640660</td>\n",
       "      <td>0.627932</td>\n",
       "      <td>0.635171</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55.190692</td>\n",
       "      <td>8.556336</td>\n",
       "      <td>0.204596</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.691486</td>\n",
       "      <td>0.701183</td>\n",
       "      <td>0.712477</td>\n",
       "      <td>0.696367</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.640313</td>\n",
       "      <td>0.652633</td>\n",
       "      <td>0.663953</td>\n",
       "      <td>0.643983</td>\n",
       "      <td>0.632746</td>\n",
       "      <td>0.646726</td>\n",
       "      <td>0.010731</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>86.076390</td>\n",
       "      <td>9.028885</td>\n",
       "      <td>0.275913</td>\n",
       "      <td>0.029844</td>\n",
       "      <td>70</td>\n",
       "      <td>{'n_estimators': 70}</td>\n",
       "      <td>0.691979</td>\n",
       "      <td>0.708416</td>\n",
       "      <td>0.714614</td>\n",
       "      <td>0.705737</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.640870</td>\n",
       "      <td>0.660926</td>\n",
       "      <td>0.666526</td>\n",
       "      <td>0.655063</td>\n",
       "      <td>0.633552</td>\n",
       "      <td>0.651387</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>97.663828</td>\n",
       "      <td>12.795977</td>\n",
       "      <td>0.306358</td>\n",
       "      <td>0.041737</td>\n",
       "      <td>90</td>\n",
       "      <td>{'n_estimators': 90}</td>\n",
       "      <td>0.694609</td>\n",
       "      <td>0.707429</td>\n",
       "      <td>0.714614</td>\n",
       "      <td>0.705244</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643597</td>\n",
       "      <td>0.659907</td>\n",
       "      <td>0.666196</td>\n",
       "      <td>0.654509</td>\n",
       "      <td>0.636019</td>\n",
       "      <td>0.652046</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.942415</td>\n",
       "      <td>1.591462</td>\n",
       "      <td>0.058625</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.651381</td>\n",
       "      <td>0.650888</td>\n",
       "      <td>0.669078</td>\n",
       "      <td>0.658721</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.594212</td>\n",
       "      <td>0.594309</td>\n",
       "      <td>0.614013</td>\n",
       "      <td>0.600688</td>\n",
       "      <td>0.590074</td>\n",
       "      <td>0.598660</td>\n",
       "      <td>0.008394</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>37.890569</td>\n",
       "      <td>4.325203</td>\n",
       "      <td>0.123103</td>\n",
       "      <td>0.015861</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>0.690171</td>\n",
       "      <td>0.702991</td>\n",
       "      <td>0.700312</td>\n",
       "      <td>0.704422</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.638792</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.649884</td>\n",
       "      <td>0.653590</td>\n",
       "      <td>0.629242</td>\n",
       "      <td>0.645282</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>62.831721</td>\n",
       "      <td>9.501772</td>\n",
       "      <td>0.186214</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.698882</td>\n",
       "      <td>0.713346</td>\n",
       "      <td>0.711491</td>\n",
       "      <td>0.709025</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.649051</td>\n",
       "      <td>0.666708</td>\n",
       "      <td>0.663122</td>\n",
       "      <td>0.659063</td>\n",
       "      <td>0.636053</td>\n",
       "      <td>0.654799</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>89.553008</td>\n",
       "      <td>14.463774</td>\n",
       "      <td>0.271370</td>\n",
       "      <td>0.026195</td>\n",
       "      <td>70</td>\n",
       "      <td>{'n_estimators': 70}</td>\n",
       "      <td>0.700033</td>\n",
       "      <td>0.711374</td>\n",
       "      <td>0.715765</td>\n",
       "      <td>0.717080</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.650265</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>0.667885</td>\n",
       "      <td>0.668492</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.659396</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>108.495598</td>\n",
       "      <td>16.168418</td>\n",
       "      <td>0.318759</td>\n",
       "      <td>0.045254</td>\n",
       "      <td>90</td>\n",
       "      <td>{'n_estimators': 90}</td>\n",
       "      <td>0.697403</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.714943</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.647270</td>\n",
       "      <td>0.673085</td>\n",
       "      <td>0.677487</td>\n",
       "      <td>0.665856</td>\n",
       "      <td>0.641159</td>\n",
       "      <td>0.660971</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        5.530161      0.536271         0.053766        0.004011   \n",
       "1       17.307498      1.239440         0.121411        0.007994   \n",
       "2       26.955016      3.128957         0.178361        0.025497   \n",
       "3       40.585612      4.652533         0.208319        0.021689   \n",
       "4       41.468254      6.151401         0.256024        0.032987   \n",
       "5        7.078377      0.816084         0.051993        0.006682   \n",
       "6       21.323907      2.623709         0.109219        0.013138   \n",
       "7       36.277406      4.429330         0.164226        0.016719   \n",
       "8       49.724756      6.115824         0.229821        0.019663   \n",
       "9       60.738212      8.817731         0.249882        0.025376   \n",
       "10       8.740726      0.954207         0.056579        0.008197   \n",
       "11      25.455367      1.819653         0.114280        0.013250   \n",
       "12      47.267535      3.130625         0.169432        0.018485   \n",
       "13      78.625676      8.368828         0.221194        0.023540   \n",
       "14      81.088351      7.619692         0.271908        0.024944   \n",
       "15      10.768281      1.539505         0.057271        0.006473   \n",
       "16      31.260707      3.113115         0.127460        0.011410   \n",
       "17      51.962351      5.990119         0.179448        0.018976   \n",
       "18      73.553722      7.736031         0.237106        0.030568   \n",
       "19      91.918373      8.668600         0.300437        0.036177   \n",
       "20      11.585349      1.196537         0.060047        0.007122   \n",
       "21      35.660682      4.929442         0.132769        0.012624   \n",
       "22      55.190692      8.556336         0.204596        0.020760   \n",
       "23      86.076390      9.028885         0.275913        0.029844   \n",
       "24      97.663828     12.795977         0.306358        0.041737   \n",
       "25      12.942415      1.591462         0.058625        0.007570   \n",
       "26      37.890569      4.325203         0.123103        0.015861   \n",
       "27      62.831721      9.501772         0.186214        0.024667   \n",
       "28      89.553008     14.463774         0.271370        0.026195   \n",
       "29     108.495598     16.168418         0.318759        0.045254   \n",
       "\n",
       "   param_n_estimators                params  split0_test_accuracy  \\\n",
       "0                  10  {'n_estimators': 10}              0.516437   \n",
       "1                  30  {'n_estimators': 30}              0.567061   \n",
       "2                  50  {'n_estimators': 50}              0.583498   \n",
       "3                  70  {'n_estimators': 70}              0.588264   \n",
       "4                  90  {'n_estimators': 90}              0.592373   \n",
       "5                  10  {'n_estimators': 10}              0.575937   \n",
       "6                  30  {'n_estimators': 30}              0.617357   \n",
       "7                  50  {'n_estimators': 50}              0.634287   \n",
       "8                  70  {'n_estimators': 70}              0.636259   \n",
       "9                  90  {'n_estimators': 90}              0.645135   \n",
       "10                 10  {'n_estimators': 10}              0.591552   \n",
       "11                 30  {'n_estimators': 30}              0.644806   \n",
       "12                 50  {'n_estimators': 50}              0.649080   \n",
       "13                 70  {'n_estimators': 70}              0.661078   \n",
       "14                 90  {'n_estimators': 90}              0.656640   \n",
       "15                 10  {'n_estimators': 10}              0.626068   \n",
       "16                 30  {'n_estimators': 30}              0.655654   \n",
       "17                 50  {'n_estimators': 50}              0.669461   \n",
       "18                 70  {'n_estimators': 70}              0.678008   \n",
       "19                 90  {'n_estimators': 90}              0.679323   \n",
       "20                 10  {'n_estimators': 10}              0.628205   \n",
       "21                 30  {'n_estimators': 30}              0.672913   \n",
       "22                 50  {'n_estimators': 50}              0.691486   \n",
       "23                 70  {'n_estimators': 70}              0.691979   \n",
       "24                 90  {'n_estimators': 90}              0.694609   \n",
       "25                 10  {'n_estimators': 10}              0.651381   \n",
       "26                 30  {'n_estimators': 30}              0.690171   \n",
       "27                 50  {'n_estimators': 50}              0.698882   \n",
       "28                 70  {'n_estimators': 70}              0.700033   \n",
       "29                 90  {'n_estimators': 90}              0.697403   \n",
       "\n",
       "    split1_test_accuracy  split2_test_accuracy  split3_test_accuracy  ...  \\\n",
       "0               0.533531              0.535427              0.518823  ...   \n",
       "1               0.583333              0.579813              0.565839  ...   \n",
       "2               0.592045              0.590334              0.586060  ...   \n",
       "3               0.600756              0.601184              0.589347  ...   \n",
       "4               0.597962              0.597238              0.591156  ...   \n",
       "5               0.587114              0.592964              0.585566  ...   \n",
       "6               0.625904              0.639816              0.626336  ...   \n",
       "7               0.647272              0.648529              0.646227  ...   \n",
       "8               0.648751              0.652474              0.650337  ...   \n",
       "9               0.644806              0.655104              0.652310  ...   \n",
       "10              0.613248              0.617458              0.617294  ...   \n",
       "11              0.654504              0.659543              0.662009  ...   \n",
       "12              0.665680              0.674010              0.678777  ...   \n",
       "13              0.675871              0.676640              0.681243  ...   \n",
       "14              0.679980              0.677955              0.680585  ...   \n",
       "15              0.630342              0.635048              0.634227  ...   \n",
       "16              0.678337              0.684366              0.679928  ...   \n",
       "17              0.688692              0.694065              0.689462  ...   \n",
       "18              0.693787              0.697682              0.699984  ...   \n",
       "19              0.696252              0.699326              0.693243  ...   \n",
       "20              0.639053              0.659050              0.648693  ...   \n",
       "21              0.690993              0.698833              0.693737  ...   \n",
       "22              0.701183              0.712477              0.696367  ...   \n",
       "23              0.708416              0.714614              0.705737  ...   \n",
       "24              0.707429              0.714614              0.705244  ...   \n",
       "25              0.650888              0.669078              0.658721  ...   \n",
       "26              0.702991              0.700312              0.704422  ...   \n",
       "27              0.713346              0.711491              0.709025  ...   \n",
       "28              0.711374              0.715765              0.717080  ...   \n",
       "29              0.718606              0.723985              0.714943  ...   \n",
       "\n",
       "    rank_test_fscore  split0_test_kappa  split1_test_kappa  split2_test_kappa  \\\n",
       "0                  5           0.434456           0.455954           0.453075   \n",
       "1                  4           0.492100           0.512435           0.503674   \n",
       "2                  3           0.511208           0.522253           0.516077   \n",
       "3                  1           0.516186           0.532388           0.528745   \n",
       "4                  2           0.521004           0.528986           0.523690   \n",
       "5                  5           0.505767           0.519083           0.522750   \n",
       "6                  4           0.552271           0.562799           0.576646   \n",
       "7                  3           0.571806           0.587935           0.586828   \n",
       "8                  2           0.574069           0.589371           0.591202   \n",
       "9                  1           0.584666           0.584755           0.594411   \n",
       "10                 5           0.524316           0.550588           0.552204   \n",
       "11                 4           0.585368           0.597401           0.600736   \n",
       "12                 3           0.590015           0.610605           0.618004   \n",
       "13                 2           0.604209           0.622724           0.621108   \n",
       "14                 1           0.598885           0.627120           0.622391   \n",
       "15                 5           0.564429           0.569494           0.573726   \n",
       "16                 4           0.597852           0.625432           0.630740   \n",
       "17                 3           0.613897           0.637007           0.641839   \n",
       "18                 2           0.624237           0.643239           0.646128   \n",
       "19                 1           0.625638           0.646238           0.647833   \n",
       "20                 5           0.566923           0.580541           0.602343   \n",
       "21                 4           0.618431           0.640877           0.647954   \n",
       "22                 3           0.640313           0.652633           0.663953   \n",
       "23                 2           0.640870           0.660926           0.666526   \n",
       "24                 1           0.643597           0.659907           0.666196   \n",
       "25                 5           0.594212           0.594309           0.614013   \n",
       "26                 4           0.638792           0.654902           0.649884   \n",
       "27                 3           0.649051           0.666708           0.663122   \n",
       "28                 2           0.650265           0.664652           0.667885   \n",
       "29                 1           0.647270           0.673085           0.677487   \n",
       "\n",
       "    split3_test_kappa  split4_test_kappa  mean_test_kappa  std_test_kappa  \\\n",
       "0            0.434335           0.443335         0.444231        0.009055   \n",
       "1            0.487696           0.503190         0.499819        0.008854   \n",
       "2            0.511640           0.523168         0.516869        0.005073   \n",
       "3            0.515077           0.527616         0.524002        0.007023   \n",
       "4            0.516920           0.523799         0.522880        0.003946   \n",
       "5            0.513864           0.512201         0.514733        0.005844   \n",
       "6            0.560217           0.554982         0.561383        0.008489   \n",
       "7            0.583978           0.572795         0.580668        0.006961   \n",
       "8            0.588727           0.578045         0.584283        0.006881   \n",
       "9            0.590973           0.578874         0.586736        0.005420   \n",
       "10           0.551157           0.537681         0.543189        0.010826   \n",
       "11           0.603231           0.591567         0.595661        0.006462   \n",
       "12           0.622958           0.602611         0.608839        0.011658   \n",
       "13           0.625771           0.603546         0.615472        0.009587   \n",
       "14           0.624991           0.606015         0.615880        0.011295   \n",
       "15           0.571556           0.566107         0.569062        0.003417   \n",
       "16           0.624605           0.615017         0.618729        0.011605   \n",
       "17           0.636136           0.617481         0.629272        0.011316   \n",
       "18           0.648053           0.629001         0.638131        0.009642   \n",
       "19           0.640170           0.633175         0.638611        0.008288   \n",
       "20           0.587852           0.577097         0.582951        0.011807   \n",
       "21           0.640660           0.627932         0.635171        0.010571   \n",
       "22           0.643983           0.632746         0.646726        0.010731   \n",
       "23           0.655063           0.633552         0.651387        0.012348   \n",
       "24           0.654509           0.636019         0.652046        0.010921   \n",
       "25           0.600688           0.590074         0.598660        0.008394   \n",
       "26           0.653590           0.629242         0.645282        0.009820   \n",
       "27           0.659063           0.636053         0.654799        0.011079   \n",
       "28           0.668492           0.645688         0.659396        0.009526   \n",
       "29           0.665856           0.641159         0.660971        0.014308   \n",
       "\n",
       "    rank_test_kappa  n_months  \n",
       "0                 5         1  \n",
       "1                 4         1  \n",
       "2                 3         1  \n",
       "3                 1         1  \n",
       "4                 2         1  \n",
       "5                 5         2  \n",
       "6                 4         2  \n",
       "7                 3         2  \n",
       "8                 2         2  \n",
       "9                 1         2  \n",
       "10                5         3  \n",
       "11                4         3  \n",
       "12                3         3  \n",
       "13                2         3  \n",
       "14                1         3  \n",
       "15                5         4  \n",
       "16                4         4  \n",
       "17                3         4  \n",
       "18                2         4  \n",
       "19                1         4  \n",
       "20                5         5  \n",
       "21                4         5  \n",
       "22                3         5  \n",
       "23                2         5  \n",
       "24                1         5  \n",
       "25                5         6  \n",
       "26                4         6  \n",
       "27                3         6  \n",
       "28                2         6  \n",
       "29                1         6  \n",
       "\n",
       "[30 rows x 47 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e31bbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='n_months'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_stat_df.groupby(\"n_months\")[\"mean_test_accuracy\"].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282fe5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_stats = []\n",
    "for n_months, sequencelength in zip(range(1, 7), range(10, 70, 10)):\n",
    "    args = TrainConfig(model=\"lightgbm\",\n",
    "                       n_months=n_months,\n",
    "                       sequencelength=sequencelength,\n",
    "                       hyperparameters={\"n_estimators\": range(10, 110, 20)})\n",
    "    best_model, train_stats = train(args)\n",
    "    lgbm_stats.append(train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ea0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_stats = []\n",
    "for n_months, sequencelength in zip(range(1, 7), range(10, 70, 10)):\n",
    "    args = TrainConfig(model=\"xgboost\",\n",
    "                       n_months=n_months,\n",
    "                       sequencelength=sequencelength,\n",
    "                       hyperparameters={\"n_estimators\": range(10, 110, 20)})\n",
    "    best_model, train_stats = train(args)\n",
    "    xgb_stats.append(train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_stats = []\n",
    "for n_months, sequencelength in zip(range(1, 7), range(10, 70, 10)):\n",
    "    args = TrainConfig(epochs=50,\n",
    "                       model=\"transformer\",\n",
    "                       n_months=n_months,\n",
    "                       sequencelength=sequencelength)\n",
    "    best_model, train_stats = train(args)\n",
    "    transformer_stats.append(train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempcnn_stats = []\n",
    "for n_months, sequencelength in zip(range(1, 7), range(10, 70, 10)):\n",
    "    args = TrainConfig(epochs=50,\n",
    "                       model=\"tempcnn\",\n",
    "                       n_months=n_months,\n",
    "                       sequencelength=sequencelength)\n",
    "    best_model, train_stats = train(args)\n",
    "    tempcnn_stats.append(train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f59c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a026fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83ec75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eae40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
